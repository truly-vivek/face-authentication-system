<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Live Face Recognition</title>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            text-align: center;
            background-color: #f5f5f5;
        }
        #video-container {
            position: relative;
            width: 640px;
            height: 480px;
            margin: 0 auto 20px;
        }
        #video {
            width: 100%;
            height: 100%;
            background-color: #000;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
            object-fit: cover;
        }
        #canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        #recognized-faces {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 20px;
            margin-top: 20px;
        }
        .face-card {
            background: white;
            border-radius: 8px;
            padding: 15px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            width: 200px;
        }
        .face-name {
            font-weight: bold;
            margin-top: 10px;
            font-size: 18px;
        }
        .confidence {
            color: #666;
            font-size: 14px;
        }
        .status {
            margin: 20px 0;
            font-size: 18px;
            color: #333;
        }
        .back-btn {
            padding: 10px 20px;
            background: #4285f4;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            margin-top: 20px;
            font-size: 16px;
        }
    </style>
</head>
<body>
    <h1>Live Face Recognition</h1>
    <p class="status" id="status">Loading models...</p>
    
    <div id="video-container">
        <video id="video" autoplay muted playsinline></video>
        <canvas id="canvas"></canvas>
    </div>
    
    <div id="recognized-faces"></div>
    
    <button class="back-btn" onclick="window.location.href='index.html'">Back to Home</button>
    
    <script>
        // Global variables
        let faceMatcher = null;
        let recognitionInterval = null;
        const recognizedFaces = {};
        let videoWidth, videoHeight;
        
        // Load models and initialize
        async function init() {
            try {
                document.getElementById('status').textContent = "Loading face recognition models...";
                
                await Promise.all([
                    faceapi.nets.tinyFaceDetector.loadFromUri('/models'),
                    faceapi.nets.faceLandmark68Net.loadFromUri('/models'),
                    faceapi.nets.faceRecognitionNet.loadFromUri('/models')
                ]);
                
                document.getElementById('status').textContent = "Models loaded. Starting camera...";
                
                // Load registered users
                await loadRegisteredUsers();
                
                // Start video stream with explicit dimensions
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: {
                        width: { ideal: 640 },
                        height: { ideal: 480 }
                    } 
                });
                
                const video = document.getElementById('video');
                video.srcObject = stream;
                
                // Wait for video metadata to load to get actual dimensions
                video.onloadedmetadata = () => {
                    videoWidth = video.videoWidth;
                    videoHeight = video.videoHeight;
                    console.log(`Video dimensions: ${videoWidth}x${videoHeight}`);
                    
                    // Set canvas dimensions explicitly
                    const canvas = document.getElementById('canvas');
                    canvas.width = videoWidth;
                    canvas.height = videoHeight;
                    
                    document.getElementById('status').textContent = "Scanning for faces...";
                    startRecognition();
                };
                
            } catch (error) {
                console.error("Initialization error:", error);
                document.getElementById('status').textContent = `Error: ${error.message}`;
            }
        }
        
        // Load all registered users from localStorage
        async function loadRegisteredUsers() {
            const registeredUsers = [];
            
            for (let i = 0; i < localStorage.length; i++) {
                const key = localStorage.key(i);
                try {
                    const user = JSON.parse(localStorage.getItem(key));
                    if (user && user.username && user.faceDescriptor) {
                        registeredUsers.push(user);
                    }
                } catch (e) {
                    console.warn("Couldn't parse user data for key:", key);
                }
            }
            
            if (registeredUsers.length === 0) {
                document.getElementById('status').textContent = "No registered users found. Please register first.";
                return;
            }
            
            // Create labeled descriptors for face recognition
            const labeledDescriptors = registeredUsers.map(user => 
                new faceapi.LabeledFaceDescriptors(
                    user.username, 
                    [new Float32Array(user.faceDescriptor)]
                )
            );
            
            faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);
            console.log(`Loaded ${registeredUsers.length} registered users`);
        }
        
        // Start continuous face recognition
        function startRecognition() {
            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');
            
            // Run recognition every 500ms
            recognitionInterval = setInterval(async () => {
                try {
                    if (!videoWidth || !videoHeight) {
                        console.warn("Video dimensions not set yet");
                        return;
                    }
                    
                    const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                        .withFaceLandmarks()
                        .withFaceDescriptors();
                    
                    // Clear previous drawings
                    const context = canvas.getContext('2d');
                    context.clearRect(0, 0, canvas.width, canvas.height);
                    
                    // Resize detections to match display size
                    const resizedDetections = faceapi.resizeResults(detections, { 
                        width: videoWidth, 
                        height: videoHeight 
                    });
                    
                    // Draw detections
                    faceapi.draw.drawDetections(canvas, resizedDetections);
                    faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
                    
                    // Process recognized faces
                    processRecognitions(resizedDetections);
                    
                } catch (error) {
                    console.error("Recognition error:", error);
                }
            }, 500);
        }
        
        // Process recognition results
        function processRecognitions(detections) {
            if (!faceMatcher || !detections || detections.length === 0) {
                updateRecognizedFacesDisplay({});
                return;
            }
            
            const currentRecognitions = {};
            
            detections.forEach(detection => {
                const bestMatch = faceMatcher.findBestMatch(detection.descriptor);
                
                if (bestMatch.label !== "unknown") {
                    currentRecognitions[bestMatch.label] = {
                        name: bestMatch.label,
                        confidence: (1 - bestMatch.distance).toFixed(2),
                        lastSeen: new Date()
                    };
                }
            });
            
            // Merge with previous recognitions
            Object.keys(currentRecognitions).forEach(name => {
                recognizedFaces[name] = currentRecognitions[name];
            });
            
            // Update display
            updateRecognizedFacesDisplay(recognizedFaces);
        }
        
        // Update the display of recognized faces
        function updateRecognizedFacesDisplay(faces) {
            const container = document.getElementById('recognized-faces');
            
            if (Object.keys(faces).length === 0) {
                container.innerHTML = '<p>No recognized faces</p>';
                return;
            }
            
            // Sort by most recently seen
            const sortedFaces = Object.values(faces).sort((a, b) => b.lastSeen - a.lastSeen);
            
            container.innerHTML = sortedFaces.map(face => `
                <div class="face-card">
                    <div class="face-name">${face.name}</div>
                    <div class="confidence">Confidence: ${face.confidence}</div>
                    <div class="time">Last seen: ${face.lastSeen.toLocaleTimeString()}</div>
                </div>
            `).join('');
        }
        
        // Clean up when leaving the page
        window.addEventListener('beforeunload', () => {
            if (recognitionInterval) {
                clearInterval(recognitionInterval);
            }
            const video = document.getElementById('video');
            if (video && video.srcObject) {
                video.srcObject.getTracks().forEach(track => track.stop());
            }
        });
        
        // Initialize when page loads
        window.addEventListener('load', init);
    </script>
</body>
</html>